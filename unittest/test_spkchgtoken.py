import torch
from f5_tts.model.utils import get_tokenizer
from safetensors.torch import load_file
import warnings; warnings.filterwarnings("ignore")
from f5_tac.model.utils import list_str_to_idx

tok_path = "/export/fs06/rphadke1/data/fisher_chunks_0.1K_v3.0/vocab.txt"
vocab_char_map, vocab_size = get_tokenizer(tok_path, "custom")

prev_ckpt_path = "/export/fs06/rphadke1/ckpts/pretrained_model_1250000.safetensors"
sd_before = load_file(prev_ckpt_path, device="cpu")
sd_before = {k.replace("ema_model.", ""): v for k, v in sd_before.items()}
# print("\n == Prev Checkpoint ==")
# print(set(sd_before.keys()))

ckpt_path = "/export/fs06/rphadke1/ckpts/fisher_chunks_0.1K_LoRAv4.4/model_120000.pt"
sd_after  = torch.load(ckpt_path,  map_location="cpu")["ema_model_state_dict"]
sd_after = {k.replace("ema_model.", ""): v for k, v in sd_after.items()}
# print("\n == New Checkpoint ==")
# print(set(sd_after.keys()))


Ib = sd_before["transformer.input_embed.proj.weight"]
Ia = sd_after["base_model.model.transformer.input_embed.proj.weight"]
Idelta = (Ib - Ia).abs()

print("\n == Mean Input Embedding Change ==")
print(Idelta.mean().item())

print("\n == Max Input Embedding Change ==")
print(Idelta.max().item())

Wb = sd_before["transformer.text_embed.text_embed.weight"]

Wa = sd_after["base_model.model.transformer.text_embed.text_embed.weight"]
spk_chg_token = "<utt>"

# 4) Metrics
speaker_chg_token_idx = list_str_to_idx([spk_chg_token], vocab_char_map=vocab_char_map)
filler_token_idx = 0

SpkWa = Wa[speaker_chg_token_idx]

FWb = Wb[filler_token_idx]
FWa = Wa[filler_token_idx]

# initpoint = torch.tensor([[-2.3092e-02, -1.0132e-03,  1.2144e-03,  7.6822e-03,  1.0844e-02,
#          -6.5742e-04,  4.7017e-03, -6.6366e-03, -1.1131e-03,  6.8121e-03,
#           9.5692e-03, -5.8038e-03,  1.2912e-02, -3.5084e-03, -4.8082e-03,
#          -6.1618e-03, -5.1146e-03, -6.0070e-04, -5.8289e-03,  4.3972e-03,
#          -9.4524e-04, -9.9139e-03,  1.6516e-02, -3.6006e-03,  9.7667e-04,
#          -4.5802e-03, -6.9654e-03, -5.3729e-03,  4.2708e-03,  4.2167e-03,
#           2.4648e-03,  9.0751e-03, -8.7123e-03,  1.6105e-02, -5.7435e-04,
#          -2.7182e-02, -9.1484e-03,  9.8479e-03, -9.6084e-03,  1.0060e-03,
#          -4.2192e-03,  1.4333e-02,  1.1265e-02,  7.1204e-03, -1.2924e-02,
#           1.2345e-03, -2.0597e-02, -2.8504e-03,  5.2370e-03, -1.0158e-02,
#          -1.0871e-02,  9.7930e-03,  3.3471e-03,  1.3537e-02, -1.4749e-02,
#          -4.3427e-03,  8.4040e-04,  2.5199e-03,  1.1321e-02,  9.3828e-03,
#          -4.2834e-03,  7.8012e-03,  6.9951e-03, -1.7711e-02, -1.2446e-02,
#          -5.5189e-03,  1.0526e-02, -6.5197e-03,  2.2408e-03,  1.7615e-03,
#          -1.0533e-02, -8.1356e-03,  1.0705e-02, -5.1459e-04, -5.4693e-03,
#           6.5063e-03,  1.3274e-04,  9.5320e-04,  2.8739e-03,  1.6553e-03,
#           9.2605e-04, -1.6212e-02, -2.1861e-03,  4.9325e-03,  7.0833e-03,
#          -2.3165e-03, -5.5818e-03,  1.0164e-02, -3.4086e-03,  6.9847e-03,
#           8.0712e-03,  6.1279e-03, -1.8522e-03, -1.3366e-02,  4.4226e-03,
#          -8.6035e-03,  2.3153e-02,  2.5615e-04,  6.9096e-03, -1.1873e-02,
#          -7.9169e-03, -1.1716e-02, -1.5413e-02,  1.0298e-02, -4.6167e-03,
#          -1.2456e-04,  1.1844e-02, -5.6690e-03, -4.6782e-03,  1.2328e-02,
#           1.6425e-02,  3.5789e-03,  1.9983e-03, -1.3896e-03, -3.5891e-03,
#           7.5403e-04, -2.1208e-02, -1.3638e-03,  7.0382e-03, -7.0047e-03,
#           7.2664e-03, -1.1180e-02, -5.1888e-03, -1.6584e-03,  9.5826e-03,
#          -1.8580e-03, -9.7399e-03,  1.5404e-02, -1.0889e-02, -1.3303e-03,
#          -8.7983e-03, -5.6184e-03,  1.1400e-02,  8.7894e-04,  1.1652e-02,
#           1.2280e-02, -1.4092e-02, -1.6290e-03,  3.3402e-04,  2.0035e-02,
#           1.7649e-02, -1.3931e-02,  4.6849e-03,  1.6257e-02, -4.8328e-03,
#           4.4448e-03, -8.7598e-03, -1.0396e-02, -9.2644e-03, -3.1658e-04,
#           8.9393e-04,  2.4037e-03,  2.5056e-02,  1.9211e-02, -3.5507e-03,
#           4.2103e-03,  1.4142e-03, -2.3001e-03,  1.6784e-03, -9.0093e-03,
#          -3.7922e-03,  3.5677e-03, -1.5531e-03, -1.4293e-02, -1.2126e-02,
#           1.2004e-02,  2.8380e-03,  1.6337e-02, -2.9977e-02, -2.0453e-02,
#          -9.6200e-03, -2.2930e-03, -7.9975e-03,  1.0282e-02,  4.7590e-03,
#          -8.1906e-03,  1.1362e-02, -2.1313e-02,  8.0099e-05,  3.8465e-03,
#          -5.7705e-03, -8.2644e-05, -1.3742e-02, -1.3804e-02, -1.5132e-02,
#           9.7495e-03, -1.6332e-02, -2.9327e-03,  2.7847e-03,  3.5295e-03,
#          -9.7809e-03, -1.6190e-02,  1.3285e-03, -2.1821e-03, -2.3456e-02,
#          -1.8759e-02, -9.2031e-03, -1.0532e-02,  9.5249e-03,  6.3583e-03,
#           6.0327e-03, -1.5449e-02, -2.2611e-02, -1.0839e-02, -3.9800e-04,
#          -1.8189e-02,  1.2096e-02,  5.7395e-03,  6.7849e-03,  5.0827e-03,
#          -1.0417e-02, -1.1969e-02,  3.7856e-03,  1.2839e-02, -1.5720e-02,
#           1.6211e-02, -4.7340e-03,  1.1408e-02,  1.2638e-02, -5.8293e-03,
#          -1.7571e-03,  8.5547e-05,  1.8944e-02, -7.2814e-04, -4.6327e-03,
#           4.7857e-03,  3.8835e-06, -1.3436e-03,  2.7927e-03,  3.3538e-03,
#           2.2473e-03, -1.3869e-03,  2.5154e-03,  4.3291e-03, -1.1126e-02,
#           7.3199e-03, -6.3614e-04, -9.2010e-03,  7.4348e-03,  2.6975e-03,
#           1.0181e-02,  2.0872e-02, -3.4835e-03, -2.4427e-02, -1.0988e-02,
#           1.9560e-02, -9.4133e-03, -4.8080e-03,  7.7583e-03, -3.9201e-04,
#          -5.9000e-03, -9.6252e-03, -1.0776e-03, -8.2420e-03,  8.0491e-03,
#           2.5623e-02,  1.0647e-02,  9.3579e-03, -9.2225e-03,  7.8725e-03,
#           1.6127e-03,  3.4377e-03,  6.3682e-04,  4.5832e-04,  1.3155e-02,
#          -3.6486e-03,  8.4666e-03,  1.0942e-02,  1.1695e-02, -5.2840e-03,
#          -6.5255e-03, -3.7498e-03,  4.2200e-03,  5.9453e-03, -7.9041e-03,
#           7.9710e-03,  9.8444e-03,  1.7813e-02,  3.7385e-03,  1.3827e-03,
#          -1.3334e-02, -1.2274e-02, -7.2758e-03, -2.7361e-03,  8.3347e-03,
#          -1.1361e-02, -3.4742e-03,  1.0581e-03, -1.4355e-03, -7.3281e-03,
#          -2.0763e-02, -4.1619e-03, -1.0482e-03, -2.9240e-03, -7.7739e-03,
#          -6.1914e-03,  1.7018e-02, -2.9217e-03, -2.4244e-02,  8.1678e-03,
#           4.8694e-03, -2.3394e-03,  9.1308e-03, -1.3048e-02, -9.0885e-03,
#          -9.4908e-03, -3.9591e-03,  1.6488e-03, -7.7086e-03,  7.6957e-03,
#           1.3143e-02, -2.3755e-02, -8.4407e-03, -2.1722e-02, -5.2843e-03,
#           1.4693e-02,  3.0583e-04,  1.4069e-02,  8.8801e-03,  1.2230e-02,
#          -8.7065e-03, -1.8850e-02,  1.7935e-03,  1.0121e-02, -6.8884e-03,
#           1.8179e-03, -2.3937e-03, -5.1648e-03,  8.6262e-03,  1.0830e-02,
#           5.3908e-03,  1.6231e-02, -2.0906e-04,  4.3178e-03,  6.2359e-03,
#          -2.3485e-03,  8.7578e-03,  1.1422e-03, -2.8555e-03,  9.8128e-03,
#           1.0832e-02,  5.7551e-03,  1.1125e-02,  6.9149e-03, -8.4167e-03,
#           1.2169e-02,  7.0089e-03,  1.1381e-02, -1.3529e-03, -1.6760e-03,
#           3.0419e-03,  1.4741e-02, -9.9793e-03,  3.1041e-03,  3.4904e-03,
#           1.7641e-02,  7.1670e-03, -2.5032e-03,  1.4149e-02, -3.3826e-03,
#          -3.7306e-03, -9.8197e-03,  2.0923e-03,  1.0597e-02, -1.4817e-02,
#          -2.8414e-03, -8.6729e-03,  7.6119e-03,  3.7642e-03,  1.1441e-02,
#           5.5673e-03, -8.5940e-03,  2.0616e-04, -3.6462e-04, -1.3361e-03,
#          -1.0263e-02,  2.5041e-03,  6.8441e-03,  2.0710e-02, -1.4629e-03,
#          -8.5968e-03, -8.7585e-03,  7.1889e-03, -7.5163e-03, -8.6843e-03,
#           1.7677e-04,  6.1370e-03, -8.5944e-03, -7.4569e-03, -4.3022e-03,
#           1.6362e-03,  1.9790e-02,  1.2285e-02,  3.1568e-03,  6.0701e-03,
#           4.7315e-03, -5.9949e-03, -8.2990e-03, -1.1486e-02,  1.8529e-02,
#          -1.7368e-02,  4.4735e-03, -1.6020e-02,  1.0162e-02, -5.0674e-03,
#           3.7598e-04, -1.6440e-02, -1.7251e-03,  1.6623e-02,  4.5842e-03,
#          -1.3531e-02, -4.3479e-03, -1.3213e-02, -1.4479e-02,  1.6743e-02,
#          -1.6995e-04,  3.0426e-03,  1.2782e-02, -6.2529e-03, -1.4317e-02,
#           1.0944e-02, -4.1697e-03,  3.1255e-03, -8.9891e-03, -1.4057e-04,
#          -1.2501e-02, -2.6111e-04, -2.0992e-03, -1.0095e-02,  4.1731e-03,
#          -2.3463e-04,  1.3385e-02,  6.1974e-03,  7.1149e-04,  1.2149e-02,
#           2.4959e-03, -2.7224e-03, -6.0791e-04,  2.4684e-02, -1.2322e-02,
#           1.0914e-02,  4.9059e-03, -1.6264e-02, -3.4602e-04,  7.9227e-03,
#           4.4851e-03,  4.1161e-03, -5.0900e-03,  2.9111e-03,  3.8280e-03,
#           1.2948e-02, -1.8139e-02, -8.8180e-03,  3.8110e-03,  1.5623e-02,
#          -6.3946e-03,  1.8224e-02, -3.7781e-03, -1.0642e-02,  7.8879e-03,
#           2.3426e-03, -5.5356e-04,  5.7932e-03, -5.0138e-04,  4.6677e-03,
#          -1.6984e-02, -1.2967e-02, -7.0005e-03,  6.1626e-03, -6.8169e-03,
#           7.6836e-03, -4.5646e-03, -3.4720e-03,  2.0717e-02,  3.7859e-03,
#           8.1022e-03,  5.1133e-03, -6.6832e-03, -5.7353e-03,  7.0553e-03,
#           2.9500e-03, -3.8873e-03, -2.1307e-02,  1.0890e-02,  4.7701e-03,
#           8.9917e-04,  3.9761e-03, -6.1779e-03, -1.6375e-02, -9.1556e-03,
#           7.6047e-03, -1.6722e-02,  1.4488e-03,  4.8418e-03,  1.7404e-02,
#          -6.0545e-03, -8.5734e-03,  9.6348e-03,  1.2574e-02, -2.2227e-02,
#           4.1670e-03,  6.6181e-03, -9.1403e-03, -1.7277e-02, -6.1806e-03,
#           3.9189e-03,  4.5906e-03,  7.0643e-04,  2.3640e-02, -1.1396e-02,
#           8.9431e-03, -2.0829e-03]])

initpoint = torch.tensor([[-1.5121e-02,  2.2179e-04, -1.8899e-03, -3.7531e-03, -9.5932e-03,
          5.8081e-04,  1.3717e-02, -6.2409e-03, -1.2505e-03,  1.1627e-02,
         -1.6571e-03,  5.4592e-03, -9.2124e-03, -5.3383e-03,  2.7638e-03,
          1.2588e-02,  1.3371e-02, -9.0094e-04, -4.5739e-03,  7.0587e-03,
         -4.1471e-03, -2.8413e-03, -1.3141e-02,  2.1369e-02,  2.4191e-02,
          2.4314e-02,  1.1499e-02,  2.4123e-04, -1.3499e-02, -1.1141e-02,
         -8.0370e-04, -8.0315e-04, -2.5704e-04, -4.9930e-04,  2.2469e-03,
          1.1263e-03, -1.4148e-04, -1.6040e-02, -1.1679e-02, -2.7498e-03,
         -8.6696e-03, -5.8003e-03, -1.0845e-02,  8.4608e-04, -4.9306e-03,
          5.1121e-03,  1.3687e-02, -1.6102e-02, -1.3859e-02,  3.0340e-03,
         -6.8317e-03, -1.4039e-02, -7.9453e-03, -1.5462e-02, -1.0133e-02,
          3.5945e-03,  2.3281e-03,  1.1015e-02,  8.6219e-03, -1.3507e-02,
         -3.0822e-03, -7.3343e-04, -8.9434e-03,  9.7190e-03,  1.3242e-02,
         -3.9576e-03, -8.8637e-03, -2.0578e-02,  3.0635e-03,  1.6441e-02,
          2.4364e-02, -1.0298e-02, -5.4228e-03, -9.2921e-03,  6.2394e-03,
          3.2641e-04,  4.1837e-03, -1.3358e-03,  3.8417e-03, -1.6721e-02,
          1.6497e-02, -1.6622e-02, -1.0853e-02,  2.4875e-03,  7.2756e-03,
         -9.6009e-03, -2.5710e-03, -1.0603e-02, -7.3926e-03,  9.3209e-04,
         -5.7160e-03,  2.9508e-02, -7.4108e-03, -2.0230e-03,  7.1919e-03,
         -2.7976e-03,  1.4566e-02, -1.5283e-02, -6.0551e-03,  8.5143e-03,
         -4.0979e-03,  6.1351e-03,  6.9975e-03,  2.3720e-03, -6.8295e-03,
          4.2882e-03, -7.7813e-03,  2.3653e-03,  2.1434e-02, -1.1564e-02,
         -3.1698e-02, -7.8211e-03,  2.4027e-02,  4.7097e-04,  2.3059e-03,
         -2.8281e-03, -3.0489e-03, -5.3315e-03, -2.7109e-03,  1.3735e-02,
          2.1159e-02, -2.3065e-03,  4.2253e-03, -1.0736e-02, -1.0152e-02,
         -1.7135e-02,  4.1533e-03,  6.3268e-06,  1.5798e-03, -3.4466e-03,
         -1.9639e-03, -5.4559e-03,  1.8426e-02, -5.3129e-03,  4.0903e-03,
         -7.7708e-04,  8.5882e-03,  9.3540e-03,  8.1872e-03, -5.5686e-03,
          1.3433e-02, -3.0583e-03,  4.7830e-04, -7.3759e-03, -5.7977e-03,
          1.5700e-02,  7.5850e-03, -7.9879e-03,  5.0959e-03,  3.5703e-03,
         -8.5850e-03, -1.0365e-02,  1.7182e-02, -1.5505e-02,  2.1095e-03,
         -3.9108e-03, -3.7326e-03, -2.1281e-03,  1.4842e-03, -1.1210e-02,
         -7.2462e-03, -1.4216e-02,  3.1806e-03,  4.6734e-03,  1.0329e-02,
         -1.1475e-02,  1.3380e-02, -3.7353e-03,  9.8544e-03, -2.6561e-03,
         -7.2032e-04,  1.8000e-02, -9.9938e-04, -3.4955e-03,  3.7688e-03,
          2.0666e-03, -1.2109e-02, -7.7025e-03, -1.5800e-02, -6.8274e-03,
         -6.6189e-04, -3.4027e-04,  5.8793e-04, -2.3047e-02,  9.4415e-03,
         -7.4423e-04,  3.7160e-04,  3.9508e-03, -1.0893e-02, -3.5627e-03,
         -7.3116e-03,  7.2553e-03,  1.4497e-02,  7.3833e-03,  7.2307e-03,
         -1.9668e-03,  1.3141e-03, -1.7187e-02,  7.8174e-03,  1.7456e-03,
          9.7013e-03, -5.1287e-03,  8.5646e-03, -1.1132e-03,  2.4076e-02,
          1.0717e-02,  3.5188e-03, -1.5871e-03,  1.8609e-02,  8.1664e-04,
         -1.7775e-03,  7.5015e-03,  5.9069e-03, -3.1963e-03, -1.9130e-03,
          5.6440e-03, -1.1123e-02,  4.4073e-03,  7.5616e-03, -1.6854e-02,
          2.3826e-02, -7.7568e-03, -6.6399e-03, -8.6411e-03,  4.4670e-03,
          8.6857e-03, -1.3790e-02, -9.5479e-03,  1.4121e-02,  6.1089e-03,
         -1.6731e-02,  1.1592e-03,  1.1397e-02, -1.2995e-02,  9.6739e-03,
         -1.2311e-02,  1.0251e-02,  4.2838e-04,  1.1610e-02, -2.2836e-03,
         -1.8120e-02,  2.6959e-03,  1.9801e-02, -2.4391e-02, -3.0055e-04,
          2.2954e-02, -1.0229e-02, -1.3043e-02, -4.9594e-03, -2.9852e-03,
          1.7827e-02,  5.0827e-04, -1.8820e-02, -1.9570e-02, -1.0096e-02,
         -6.0014e-03, -4.0537e-04,  1.1682e-02, -8.9689e-03,  6.5175e-04,
          2.3963e-03, -2.0681e-02, -1.8487e-03, -2.5587e-03,  6.0121e-03,
          1.3539e-02,  3.9781e-03,  2.3331e-03,  4.9209e-03, -3.7056e-03,
          2.0485e-02,  4.2262e-03, -6.7785e-03,  3.6307e-03,  6.1594e-03,
         -4.1247e-03, -4.9506e-03,  3.5021e-03,  2.1372e-02, -4.2955e-03,
          6.6496e-03, -5.8389e-03, -5.8087e-03, -1.5604e-02,  4.1921e-06,
         -4.0506e-03, -9.3162e-03,  2.7257e-03, -2.2251e-03,  5.0963e-03,
         -1.3365e-02,  1.0472e-02,  1.2091e-02,  2.3085e-03, -1.7004e-02,
         -8.4796e-03,  6.4389e-03,  1.2065e-02, -9.4827e-03,  6.9521e-03,
         -1.8217e-02,  2.1586e-03, -2.9775e-03, -5.9055e-03, -1.4338e-02,
         -4.3208e-03,  3.7620e-03,  3.2044e-03,  1.1207e-03, -1.8169e-03,
         -6.5014e-03,  2.0834e-02, -2.0713e-02, -2.6599e-03, -1.1559e-02,
         -2.2556e-02,  1.2133e-02,  4.7931e-03, -6.6541e-04,  2.9372e-04,
          4.3696e-03, -1.6916e-02, -5.2280e-03, -8.2715e-03,  1.2603e-02,
         -1.5658e-03,  5.3685e-03, -1.0826e-02,  7.7196e-03, -7.6037e-03,
          4.5724e-04,  1.2295e-02, -3.6465e-03, -7.2118e-03, -1.1674e-03,
         -1.2423e-02, -8.5100e-03,  6.6040e-03, -8.4293e-03, -1.3541e-02,
         -7.1149e-03, -3.1708e-03,  3.7416e-03,  1.2324e-02,  2.4669e-02,
         -6.6917e-03, -3.9037e-03, -6.2533e-03,  1.6724e-02,  2.6860e-03,
          1.0567e-02,  6.0540e-03, -1.3282e-03,  7.4833e-03, -1.5181e-02,
         -1.9661e-02, -2.0853e-03, -6.2780e-03,  1.5149e-02,  1.2632e-02,
          2.4907e-02, -6.9842e-03,  5.2421e-03, -3.9627e-03, -1.4506e-02,
         -3.6281e-03,  1.8420e-02,  6.9819e-04,  1.0837e-02,  1.5305e-02,
          1.0967e-02,  4.9952e-03,  1.1590e-02, -6.8161e-03,  1.0430e-02,
         -2.0934e-03, -1.3647e-03, -2.6320e-03, -1.8081e-02, -1.5082e-02,
          5.7767e-03,  7.2625e-03, -1.1168e-02, -1.8110e-03,  1.0335e-02,
          1.6853e-02,  4.4808e-03, -6.9513e-04,  3.0821e-03, -5.6892e-03,
          1.1588e-03,  8.1035e-03,  6.9025e-03,  1.0829e-02,  2.9424e-03,
          7.6222e-03, -2.1880e-02, -1.3930e-02, -5.7700e-04,  6.9286e-03,
          1.4833e-02,  9.4445e-03,  5.8561e-03,  2.2072e-03, -6.2725e-03,
          1.3740e-02,  4.7687e-03, -9.4847e-03,  2.2650e-03,  1.1150e-02,
          1.2195e-02, -1.8531e-02,  2.3755e-03,  1.7951e-02, -5.4141e-03,
         -1.8224e-02,  1.2428e-03, -1.6642e-03, -1.4410e-02,  5.6118e-04,
         -9.7827e-04, -4.2043e-03,  5.7814e-04,  1.2117e-02,  1.6816e-02,
          8.9031e-03, -3.3235e-03,  1.2432e-02, -2.9324e-03,  9.1625e-03,
         -5.7104e-03, -2.8300e-03,  7.1603e-03, -4.4037e-03,  8.3882e-03,
         -6.0440e-03, -8.6329e-04,  2.1470e-02, -1.9808e-02,  5.2725e-03,
         -1.2133e-02, -8.8304e-03,  1.0114e-02, -2.0185e-03, -1.5051e-02,
          4.0799e-05, -1.5228e-03,  7.6111e-04,  1.2652e-02, -1.0493e-02,
         -1.4178e-03, -1.8410e-03,  8.9205e-03, -6.0519e-03,  1.3962e-03,
         -1.0050e-02, -4.2799e-03, -1.1473e-02,  1.2106e-02, -1.4032e-02,
         -9.1968e-03, -2.5799e-02,  5.6100e-03,  1.1772e-02,  1.4644e-02,
         -7.9295e-03,  8.5066e-03, -2.7137e-03,  3.9064e-03, -9.3018e-03,
          7.1122e-03,  4.3105e-03,  7.0303e-03, -2.9169e-03, -7.1869e-03,
         -1.2888e-02,  3.1540e-02, -5.4368e-03,  1.4312e-03,  1.6782e-02,
          1.1173e-02,  1.8401e-02, -4.7094e-03, -9.8835e-03,  8.1127e-03,
          5.9028e-03,  1.0526e-02,  3.2049e-03, -7.5358e-03, -1.7708e-02,
          1.2633e-03, -5.5477e-03,  6.1595e-03,  5.0368e-03,  1.3913e-02,
          1.4081e-03,  1.2874e-02, -1.8405e-03, -5.4794e-04, -5.3531e-03,
          8.2627e-03, -2.0364e-02, -5.5994e-03,  1.4629e-04, -1.2855e-02,
         -5.4474e-03, -6.7717e-03, -1.2246e-02,  6.3900e-03,  6.9365e-03,
          1.2266e-03, -1.1551e-02]])

print("\n == Mean Speaker Change Token Embedding Change ==")
print((SpkWa - initpoint).abs().mean().item())

print("\n == Max Speaker Change Token Embedding Change ==")
print((SpkWa - initpoint).abs().max().item())

print("\n == Mean Filler Token Embedding Change ==")
print((FWa - FWb).abs().mean().item())

print("\n == Max Filler Token Embedding Change ==")
print((FWa - FWb).abs().max().item())

from f5_tac.model.reccfm import CFMWithTACRecon
from f5_tac.model.backbones.dittac import DiTWithTAC

from f5_tac.configs.model_kwargs import mel_spec_kwargs, dit_cfg, lora_configv2

from peft import get_peft_model

# --- 4. Instantiate Your New Models ---
print("\nInstantiating F5-TAC models...")
transformer_backbone = DiTWithTAC(
    **dit_cfg,
    num_speakers=2, # Critical for TAC blocks
    text_num_embeds=vocab_size,
    mel_dim=mel_spec_kwargs["n_mel_channels"]
)

model = CFMWithTACRecon(
    transformer=transformer_backbone,
    mel_spec_kwargs=mel_spec_kwargs,
    vocab_char_map=vocab_char_map,
)

model = get_peft_model(model, lora_configv2)

model.load_state_dict(sd_after, strict=False)

alphas = []
for i, block in enumerate(model.transformer.transformer_blocks):
    alpha_val = block.tac.alpha.item()
    alphas.append(alpha_val)
    print(f"Layer {i}: TAC alpha = {alpha_val:.5f}")