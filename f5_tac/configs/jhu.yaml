# ----------------------- F5-TAC Finetune Config ----------------------- #
exp_name: TAC-Scratch-5000

dataset_name: data/fisher/lhotse_manifests/fixed
val_dataset_name: data/fisher_chunks
data_root: /export/fs06/rphadke1

tokenizer: custom
tokenizer_path: /export/fs06/rphadke1/data/vocab_files/vocab_v2.1.txt

pretrain: null
finetune: true

learning_rate: 1e-8
epochs: 1000

batch_size_per_gpu: 8000
batch_size_type: frame
max_samples: 64
grad_accumulation_steps: 4
max_grad_norm: 1.0

save_per_updates: 10000
keep_last_n_checkpoints: 0
last_per_updates: 1000
val_per_updates: 100

train_length: 5000
val_length: 10

early_stopping_threshold: 20

bnb_optimizer: true
log_samples: true

logger: wandb