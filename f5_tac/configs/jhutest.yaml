# ----------------------- F5-TAC Finetune Config ----------------------- #
exp_name: CA-FT-1000

dataset_name: data/fisher/lhotse_manifests/fixed
val_dataset_name: data/fisher_chunks
data_root: /export/fs06/rphadke1

tokenizer: custom
tokenizer_path: /export/fs06/rphadke1/data/vocab_files/vocab_v2.1.txt

pretrain: /export/fs06/rphadke1/ckpts/pretrained_model_1250000.safetensors
finetune: true

learning_rate: 1e-8
epochs: 500

batch_size_per_gpu: 8000
batch_size_type: frame
max_samples: 64
grad_accumulation_steps: 4
max_grad_norm: 1.0

save_per_updates: 10000
keep_last_n_checkpoints: 0
last_per_updates: 1000
val_per_updates: 100

train_length: 1000
val_length: 5

early_stopping_threshold: 20

bnb_optimizer: false
log_samples: true

logger: wandb