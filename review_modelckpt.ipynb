{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8aba790-326f-4368-a633-00d73ca5227e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting f5_tts\n",
      "  Downloading f5_tts-1.1.7-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (4.52.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (2.5.1)\n",
      "Requirement already satisfied: jieba in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.42.1)\n",
      "Requirement already satisfied: x_transformers>=1.31.14 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (2.3.23)\n",
      "Requirement already satisfied: pydantic<=2.10.6 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (2.10.1)\n",
      "Requirement already satisfied: transformers_stream_generator in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.0.5)\n",
      "Requirement already satisfied: librosa in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.11.0)\n",
      "Requirement already satisfied: datasets in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (3.6.0)\n",
      "Requirement already satisfied: gradio<=5.35.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (5.34.2)\n",
      "Requirement already satisfied: torchaudio>=2.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (2.5.1)\n",
      "Requirement already satisfied: wandb in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.20.1)\n",
      "Requirement already satisfied: pypinyin in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.54.0)\n",
      "Requirement already satisfied: bitsandbytes>0.37.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.46.0)\n",
      "Requirement already satisfied: pydub in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.25.1)\n",
      "Requirement already satisfied: soundfile in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.13.1)\n",
      "Requirement already satisfied: safetensors in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.5.3)\n",
      "Requirement already satisfied: click in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from f5_tts) (8.0.4)\n",
      "Requirement already satisfied: accelerate>=0.33.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (1.8.1)\n",
      "Requirement already satisfied: vocos in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.1.0)\n",
      "Requirement already satisfied: unidecode in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from f5_tts) (1.3.6)\n",
      "Requirement already satisfied: ema_pytorch>=0.5.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.7.7)\n",
      "Requirement already satisfied: torchdiffeq in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (0.2.5)\n",
      "Requirement already satisfied: matplotlib in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from f5_tts) (3.8.4)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (4.67.1)\n",
      "Requirement already satisfied: cached_path in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (1.7.3)\n",
      "Requirement already satisfied: hydra-core>=1.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (1.3.2)\n",
      "Requirement already satisfied: numpy<=1.26.4 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from f5_tts) (1.26.4)\n",
      "Requirement already satisfied: tomli in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from f5_tts) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from accelerate>=0.33.0->f5_tts) (23.0)\n",
      "Requirement already satisfied: psutil in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from accelerate>=0.33.0->f5_tts) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from accelerate>=0.33.0->f5_tts) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from accelerate>=0.33.0->f5_tts) (0.33.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (3.7.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (2.1.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (4.12.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.13.0)\n",
      "Requirement already satisfied: gradio-client==1.10.3 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (1.10.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.27.2)\n",
      "Requirement already satisfied: ffmpy in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.6.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.1.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.12.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (2.2.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.1.6)\n",
      "Requirement already satisfied: orjson~=3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (3.10.18)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.34.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.46.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (3.1.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (24.1.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.0.20)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (0.115.13)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from gradio<=5.35.0->f5_tts) (9.4.0)\n",
      "Requirement already satisfied: fsspec in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (2024.10.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (10.4)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from hydra-core>=1.3.0->f5_tts) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from hydra-core>=1.3.0->f5_tts) (4.9.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from pydantic<=2.10.6->f5_tts) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from pydantic<=2.10.6->f5_tts) (2.27.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (3.1.0)\n",
      "Requirement already satisfied: networkx in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (3.4.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (2.21.5)\n",
      "Requirement already satisfied: filelock in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from torch>=2.0.0->f5_tts) (12.4.5.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->f5_tts) (1.3.0)\n",
      "Requirement already satisfied: loguru in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from x_transformers>=1.31.14->f5_tts) (0.7.3)\n",
      "Requirement already satisfied: einops>=0.8.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from x_transformers>=1.31.14->f5_tts) (0.8.1)\n",
      "Requirement already satisfied: einx>=0.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from x_transformers>=1.31.14->f5_tts) (0.3.0)\n",
      "Requirement already satisfied: rich<14.0,>=12.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from cached_path->f5_tts) (13.9.4)\n",
      "Requirement already satisfied: boto3<2.0,>=1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from cached_path->f5_tts) (1.38.41)\n",
      "Requirement already satisfied: requests in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from cached_path->f5_tts) (2.32.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from cached_path->f5_tts) (2.19.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from datasets->f5_tts) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from datasets->f5_tts) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from datasets->f5_tts) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from datasets->f5_tts) (0.3.8)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (0.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (3.0.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (1.0.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from librosa->f5_tts) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from librosa->f5_tts) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from librosa->f5_tts) (1.2.2)\n",
      "Requirement already satisfied: pooch>=1.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from librosa->f5_tts) (1.4.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (0.61.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from librosa->f5_tts) (0.5.0.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from soundfile->f5_tts) (1.15.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from matplotlib->f5_tts) (0.12.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from transformers->f5_tts) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from transformers->f5_tts) (2024.11.6)\n",
      "Requirement already satisfied: encodec==0.1.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from vocos->f5_tts) (0.1.1)\n",
      "Requirement already satisfied: platformdirs in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from wandb->f5_tts) (4.3.6)\n",
      "Requirement already satisfied: setproctitle in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from wandb->f5_tts) (1.3.6)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from wandb->f5_tts) (3.1.44)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from wandb->f5_tts) (2.30.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from wandb->f5_tts) (5.28.3)\n",
      "Requirement already satisfied: idna>=2.8 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.35.0->f5_tts) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.35.0->f5_tts) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.35.0->f5_tts) (1.3.1)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.41 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from boto3<2.0,>=1.0->cached_path->f5_tts) (1.38.41)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from boto3<2.0,>=1.0->cached_path->f5_tts) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from boto3<2.0,>=1.0->cached_path->f5_tts) (0.13.0)\n",
      "Requirement already satisfied: pycparser in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from cffi>=1.0->soundfile->f5_tts) (2.21)\n",
      "Requirement already satisfied: frozendict in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from einx>=0.3.0->x_transformers>=1.31.14->f5_tts) (2.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (3.11.7)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->f5_tts) (4.0.12)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (2.36.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (2.23.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (2.7.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (2.4.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (1.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.35.0->f5_tts) (1.0.6)\n",
      "Requirement already satisfied: certifi in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.35.0->f5_tts) (2024.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.35.0->f5_tts) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.33.0->f5_tts) (1.1.5)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa->f5_tts) (0.44.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio<=5.35.0->f5_tts) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio<=5.35.0->f5_tts) (2024.1)\n",
      "Requirement already satisfied: appdirs in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from pooch>=1.1->librosa->f5_tts) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->f5_tts) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from requests->cached_path->f5_tts) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from requests->cached_path->f5_tts) (2.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from rich<14.0,>=12.1->cached_path->f5_tts) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from rich<14.0,>=12.1->cached_path->f5_tts) (3.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa->f5_tts) (2.2.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.35.0->f5_tts) (1.5.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (1.18.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (2.4.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (1.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->gradio-client==1.10.3->gradio<=5.35.0->f5_tts) (0.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->f5_tts) (5.0.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (5.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (0.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.1->cached_path->f5_tts) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /nas/longleaf/home/rphadke/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5_tts) (0.6.1)\n",
      "Installing collected packages: f5_tts\n",
      "Successfully installed f5_tts-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install f5_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f56744-0917-450a-b28a-b29e8c48b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from safetensors.torch import load_file\n",
    "from f5_tts.model.utils import list_str_to_idx, get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "946e9076-3475-4376-aab4-43f19ba952e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_lora_weights(sd):\n",
    "    # find all LoRA params in the after-finetuned checkpoint\n",
    "    lora_items = {k: v for k,v in sd.items() if \".lora_\" in k and isinstance(v, torch.Tensor)}\n",
    "    if not lora_items:\n",
    "        print(\"No LoRA weights found in this checkpoint.\")\n",
    "        return\n",
    "\n",
    "    print(\"LoRA adapter parameter stats:\\n\")\n",
    "    total_norm2 = 0.0\n",
    "    total_elements = 0\n",
    "    for name, tensor in sorted(lora_items.items()):\n",
    "        t = tensor.cpu()\n",
    "        mean_abs = t.abs().mean().item()\n",
    "        max_abs  = t.abs().max().item()\n",
    "        norm2    = t.norm().item()\n",
    "        total_norm2 += norm2**2\n",
    "        total_elements += t.numel()\n",
    "        print(f\"{name:60s}  shape={tuple(t.shape)}  mean|·|={mean_abs:.3e} max|·|={max_abs:.3e} ‖·‖₂={norm2:.3e}\")\n",
    "\n",
    "    overall_fro = total_norm2**0.5\n",
    "    avg_norm    = overall_fro / (total_elements**0.5)\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"  Total LoRA parameters : {total_elements:,}\")\n",
    "    print(f\"  Combined Frobenius ‖Δ‖₂ : {overall_fro:.3e}\")\n",
    "    print(f\"  Avg per-param scale    : {avg_norm:.3e}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b46d14-d934-4ecf-a365-691e784e6a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == Prior Checkpoint ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1548620/732349108.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd_after  = torch.load(after_ckpt,  map_location=\"cpu\")[\"model_state_dict\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == New Checkpoint ==\n"
     ]
    }
   ],
   "source": [
    "# Path to your checkpoints\n",
    "before_ckpt = \"/work/users/r/p/rphadke/JSALT/ckpts/pretrained_model_1250000.safetensors\"\n",
    "after_ckpt = \"/work/users/r/p/rphadke/JSALT/ckpts/fisher_chunks_1K_LoRAv3.3/model_75000.pt\"\n",
    "tok_path = \"/work/users/r/p/rphadke/JSALT/fisher_chunks_0.1K_v2/vocab.txt\"\n",
    "vocab_char_map, vocab_size = get_tokenizer(tok_path, \"custom\")\n",
    "\n",
    "# ID of your new speaker token (e.g. tokenizer.convert_tokens_to_ids(\"<spk>\"))\n",
    "spk_chg_token = \"-\"\n",
    "\n",
    "    # 1) Load state dicts\n",
    "sd_before = load_file(before_ckpt, device=\"cpu\")\n",
    "print(\"\\n == Prior Checkpoint ==\")\n",
    "# print(set(sd_before.keys()))\n",
    "sd_after  = torch.load(after_ckpt,  map_location=\"cpu\")[\"model_state_dict\"]\n",
    "sd_after = {k.replace(\"ema_model.\", \"\"): v for k, v in sd_after.items()}\n",
    "print(\"\\n == New Checkpoint ==\")\n",
    "# print(set(sd_after.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a484be-6223-42e3-a1fa-3f74c6574f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Text Embedding Drift ==\n",
      "→ Mean text embedding matrix change |Δ| overall:                  0.000106\n",
      "→ Max |Δ| on token tensor([[13]]): 0.000003\n",
      "\n",
      "== Input Embedding Drift ==\n",
      "→ Mean input embedding weight change |Δ| overall:                  0.000918\n",
      "== LoRA Weight Scales ==\n",
      "LoRA adapter parameter stats:\n",
      "\n",
      "base_model.model.transformer.text_embed.text_blocks.0.pwconv1.lora_A.default.weight  shape=(64, 512)  mean|·|=2.220e-02 max|·|=4.427e-02 ‖·‖₂=4.636e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.0.pwconv1.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.179e-06 max|·|=8.920e-05 ‖·‖₂=3.179e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.0.pwconv2.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.138e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.0.pwconv2.lora_B.default.weight  shape=(512, 64)  mean|·|=1.286e-05 max|·|=1.160e-04 ‖·‖₂=3.125e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.1.pwconv1.lora_A.default.weight  shape=(64, 512)  mean|·|=2.205e-02 max|·|=4.422e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.1.pwconv1.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.005e-05 max|·|=7.742e-05 ‖·‖₂=3.424e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.1.pwconv2.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.132e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.1.pwconv2.lora_B.default.weight  shape=(512, 64)  mean|·|=1.169e-05 max|·|=9.868e-05 ‖·‖₂=2.845e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.2.pwconv1.lora_A.default.weight  shape=(64, 512)  mean|·|=2.198e-02 max|·|=4.428e-02 ‖·‖₂=4.605e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.2.pwconv1.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.505e-06 max|·|=9.023e-05 ‖·‖₂=3.303e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.2.pwconv2.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.129e-02 ‖·‖₂=4.624e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.2.pwconv2.lora_B.default.weight  shape=(512, 64)  mean|·|=1.052e-05 max|·|=8.405e-05 ‖·‖₂=2.536e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.3.pwconv1.lora_A.default.weight  shape=(64, 512)  mean|·|=2.213e-02 max|·|=4.427e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.3.pwconv1.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.234e-05 max|·|=1.427e-04 ‖·‖₂=4.467e-03\n",
      "base_model.model.transformer.text_embed.text_blocks.3.pwconv2.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.141e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.text_embed.text_blocks.3.pwconv2.lora_B.default.weight  shape=(512, 64)  mean|·|=2.108e-05 max|·|=1.531e-04 ‖·‖₂=5.078e-03\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.145e-02 ‖·‖₂=4.629e+00\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=2.346e-05 max|·|=3.104e-04 ‖·‖₂=8.410e-03\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.184e-02 ‖·‖₂=4.621e+00\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.296e-04 max|·|=1.033e-03 ‖·‖₂=4.603e-02\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.149e-02 ‖·‖₂=4.617e+00\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=2.052e-05 max|·|=2.740e-04 ‖·‖₂=8.055e-03\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.559e-02 max|·|=3.218e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.0.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.302e-04 max|·|=9.330e-04 ‖·‖₂=4.443e-02\n",
      "base_model.model.transformer.transformer_blocks.0.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.153e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.0.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=5.415e-05 max|·|=9.009e-04 ‖·‖₂=2.705e-02\n",
      "base_model.model.transformer.transformer_blocks.0.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.264e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.0.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.724e-04 max|·|=1.390e-02 ‖·‖₂=1.109e-01\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.154e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=3.357e-05 max|·|=4.561e-04 ‖·‖₂=1.312e-02\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.195e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.218e-04 max|·|=1.011e-03 ‖·‖₂=4.141e-02\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.153e-02 ‖·‖₂=4.618e+00\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=3.623e-05 max|·|=5.386e-04 ‖·‖₂=1.453e-02\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.197e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.1.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.128e-04 max|·|=8.265e-04 ‖·‖₂=3.775e-02\n",
      "base_model.model.transformer.transformer_blocks.1.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.200e-02 ‖·‖₂=4.616e+00\n",
      "base_model.model.transformer.transformer_blocks.1.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.201e-04 max|·|=9.310e-04 ‖·‖₂=5.768e-02\n",
      "base_model.model.transformer.transformer_blocks.1.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.103e-02 max|·|=2.270e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.1.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.450e-04 max|·|=9.802e-04 ‖·‖₂=4.855e-02\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.172e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.521e-05 max|·|=6.160e-04 ‖·‖₂=3.278e-02\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.173e-02 ‖·‖₂=4.614e+00\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.495e-04 max|·|=6.351e-04 ‖·‖₂=4.783e-02\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.166e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.051e-04 max|·|=7.760e-04 ‖·‖₂=3.626e-02\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.186e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.10.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.623e-04 max|·|=6.357e-04 ‖·‖₂=5.029e-02\n",
      "base_model.model.transformer.transformer_blocks.10.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.186e-02 ‖·‖₂=4.617e+00\n",
      "base_model.model.transformer.transformer_blocks.10.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.208e-04 max|·|=8.191e-04 ‖·‖₂=5.821e-02\n",
      "base_model.model.transformer.transformer_blocks.10.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.106e-02 max|·|=2.278e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.10.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.557e-04 max|·|=8.129e-04 ‖·‖₂=5.031e-02\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.196e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.459e-05 max|·|=5.930e-04 ‖·‖₂=3.224e-02\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.169e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.356e-04 max|·|=7.202e-04 ‖·‖₂=4.402e-02\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.172e-02 ‖·‖₂=4.614e+00\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.001e-04 max|·|=8.104e-04 ‖·‖₂=3.494e-02\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.177e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.11.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.592e-04 max|·|=5.935e-04 ‖·‖₂=4.901e-02\n",
      "base_model.model.transformer.transformer_blocks.11.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.555e-02 max|·|=3.173e-02 ‖·‖₂=4.602e+00\n",
      "base_model.model.transformer.transformer_blocks.11.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.308e-04 max|·|=8.889e-04 ‖·‖₂=6.233e-02\n",
      "base_model.model.transformer.transformer_blocks.11.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.269e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.11.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.560e-04 max|·|=8.619e-04 ‖·‖₂=5.034e-02\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.171e-02 ‖·‖₂=4.618e+00\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.714e-05 max|·|=7.002e-04 ‖·‖₂=2.752e-02\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.171e-02 ‖·‖₂=4.621e+00\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.587e-04 max|·|=1.025e-03 ‖·‖₂=5.176e-02\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.172e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.492e-05 max|·|=6.211e-04 ‖·‖₂=2.691e-02\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.182e-02 ‖·‖₂=4.634e+00\n",
      "base_model.model.transformer.transformer_blocks.12.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.565e-04 max|·|=6.667e-04 ‖·‖₂=4.929e-02\n",
      "base_model.model.transformer.transformer_blocks.12.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.183e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.12.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.124e-04 max|·|=9.208e-04 ‖·‖₂=5.615e-02\n",
      "base_model.model.transformer.transformer_blocks.12.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.273e-02 ‖·‖₂=4.629e+00\n",
      "base_model.model.transformer.transformer_blocks.12.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.614e-04 max|·|=1.162e-03 ‖·‖₂=5.367e-02\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.183e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.844e-05 max|·|=6.343e-04 ‖·‖₂=3.048e-02\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.178e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.426e-04 max|·|=7.889e-04 ‖·‖₂=4.723e-02\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.175e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.812e-05 max|·|=6.182e-04 ‖·‖₂=3.102e-02\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.186e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.13.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.535e-04 max|·|=7.703e-04 ‖·‖₂=4.981e-02\n",
      "base_model.model.transformer.transformer_blocks.13.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.197e-02 ‖·‖₂=4.621e+00\n",
      "base_model.model.transformer.transformer_blocks.13.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.228e-04 max|·|=1.149e-03 ‖·‖₂=6.045e-02\n",
      "base_model.model.transformer.transformer_blocks.13.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.103e-02 max|·|=2.271e-02 ‖·‖₂=4.614e+00\n",
      "base_model.model.transformer.transformer_blocks.13.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.712e-04 max|·|=1.024e-03 ‖·‖₂=5.568e-02\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.183e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.707e-05 max|·|=6.665e-04 ‖·‖₂=2.672e-02\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.183e-02 ‖·‖₂=4.617e+00\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.421e-04 max|·|=9.261e-04 ‖·‖₂=4.663e-02\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.178e-02 ‖·‖₂=4.616e+00\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.783e-05 max|·|=6.761e-04 ‖·‖₂=2.761e-02\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.558e-02 max|·|=3.182e-02 ‖·‖₂=4.608e+00\n",
      "base_model.model.transformer.transformer_blocks.14.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.487e-04 max|·|=8.187e-04 ‖·‖₂=4.794e-02\n",
      "base_model.model.transformer.transformer_blocks.14.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.205e-02 ‖·‖₂=4.616e+00\n",
      "base_model.model.transformer.transformer_blocks.14.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.262e-04 max|·|=9.956e-04 ‖·‖₂=6.155e-02\n",
      "base_model.model.transformer.transformer_blocks.14.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.275e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.14.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.598e-04 max|·|=8.615e-04 ‖·‖₂=5.148e-02\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.177e-02 ‖·‖₂=4.624e+00\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.150e-04 max|·|=7.129e-04 ‖·‖₂=3.909e-02\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.557e-02 max|·|=3.183e-02 ‖·‖₂=4.606e+00\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.510e-04 max|·|=1.135e-03 ‖·‖₂=4.901e-02\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.568e-02 max|·|=3.180e-02 ‖·‖₂=4.635e+00\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.188e-04 max|·|=6.972e-04 ‖·‖₂=3.985e-02\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.191e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.15.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.552e-04 max|·|=7.844e-04 ‖·‖₂=4.949e-02\n",
      "base_model.model.transformer.transformer_blocks.15.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.191e-02 ‖·‖₂=4.630e+00\n",
      "base_model.model.transformer.transformer_blocks.15.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.281e-04 max|·|=9.703e-04 ‖·‖₂=6.092e-02\n",
      "base_model.model.transformer.transformer_blocks.15.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.288e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.15.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.588e-04 max|·|=8.464e-04 ‖·‖₂=5.115e-02\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.192e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.625e-04 max|·|=9.683e-04 ‖·‖₂=5.483e-02\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.187e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.797e-04 max|·|=9.499e-04 ‖·‖₂=5.711e-02\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.186e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.673e-04 max|·|=9.992e-04 ‖·‖₂=5.621e-02\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.205e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.16.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.779e-04 max|·|=9.166e-04 ‖·‖₂=5.609e-02\n",
      "base_model.model.transformer.transformer_blocks.16.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.195e-02 ‖·‖₂=4.615e+00\n",
      "base_model.model.transformer.transformer_blocks.16.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.333e-04 max|·|=8.901e-04 ‖·‖₂=6.331e-02\n",
      "base_model.model.transformer.transformer_blocks.16.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.278e-02 ‖·‖₂=4.631e+00\n",
      "base_model.model.transformer.transformer_blocks.16.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.583e-04 max|·|=8.230e-04 ‖·‖₂=5.042e-02\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.572e-02 max|·|=3.174e-02 ‖·‖₂=4.643e+00\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.188e-04 max|·|=7.924e-04 ‖·‖₂=3.967e-02\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.180e-02 ‖·‖₂=4.616e+00\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.464e-04 max|·|=7.977e-04 ‖·‖₂=4.679e-02\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.186e-02 ‖·‖₂=4.629e+00\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.190e-04 max|·|=8.523e-04 ‖·‖₂=4.047e-02\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.186e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.17.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.586e-04 max|·|=7.587e-04 ‖·‖₂=5.018e-02\n",
      "base_model.model.transformer.transformer_blocks.17.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.186e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.17.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.413e-04 max|·|=1.175e-03 ‖·‖₂=6.724e-02\n",
      "base_model.model.transformer.transformer_blocks.17.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.108e-02 max|·|=2.280e-02 ‖·‖₂=4.629e+00\n",
      "base_model.model.transformer.transformer_blocks.17.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.578e-04 max|·|=9.617e-04 ‖·‖₂=5.099e-02\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.196e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.306e-04 max|·|=7.903e-04 ‖·‖₂=4.327e-02\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.558e-02 max|·|=3.185e-02 ‖·‖₂=4.610e+00\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.620e-04 max|·|=8.548e-04 ‖·‖₂=5.224e-02\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.200e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.328e-04 max|·|=9.492e-04 ‖·‖₂=4.458e-02\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.195e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.18.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.509e-04 max|·|=6.866e-04 ‖·‖₂=4.809e-02\n",
      "base_model.model.transformer.transformer_blocks.18.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.573e-02 max|·|=3.217e-02 ‖·‖₂=4.645e+00\n",
      "base_model.model.transformer.transformer_blocks.18.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.328e-04 max|·|=8.970e-04 ‖·‖₂=6.422e-02\n",
      "base_model.model.transformer.transformer_blocks.18.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.105e-02 max|·|=2.307e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.18.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.792e-04 max|·|=9.514e-04 ‖·‖₂=5.709e-02\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.187e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.293e-04 max|·|=7.570e-04 ‖·‖₂=4.257e-02\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.569e-02 max|·|=3.198e-02 ‖·‖₂=4.632e+00\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.436e-04 max|·|=7.768e-04 ‖·‖₂=4.667e-02\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.186e-02 ‖·‖₂=4.631e+00\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.418e-04 max|·|=7.378e-04 ‖·‖₂=4.633e-02\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.240e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.19.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.770e-04 max|·|=8.503e-04 ‖·‖₂=5.608e-02\n",
      "base_model.model.transformer.transformer_blocks.19.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.222e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.19.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.566e-04 max|·|=1.160e-03 ‖·‖₂=7.479e-02\n",
      "base_model.model.transformer.transformer_blocks.19.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.105e-02 max|·|=2.304e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.19.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.767e-04 max|·|=1.016e-03 ‖·‖₂=5.644e-02\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.202e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=6.324e-05 max|·|=6.435e-04 ‖·‖₂=2.665e-02\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.191e-02 ‖·‖₂=4.620e+00\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.280e-04 max|·|=9.545e-04 ‖·‖₂=4.292e-02\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.227e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=6.185e-05 max|·|=7.864e-04 ‖·‖₂=2.659e-02\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.182e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.2.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.389e-04 max|·|=6.671e-04 ‖·‖₂=4.450e-02\n",
      "base_model.model.transformer.transformer_blocks.2.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.190e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.2.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.303e-04 max|·|=7.800e-04 ‖·‖₂=6.095e-02\n",
      "base_model.model.transformer.transformer_blocks.2.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.103e-02 max|·|=2.268e-02 ‖·‖₂=4.612e+00\n",
      "base_model.model.transformer.transformer_blocks.2.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.499e-04 max|·|=1.061e-03 ‖·‖₂=4.998e-02\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.569e-02 max|·|=3.198e-02 ‖·‖₂=4.632e+00\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.428e-04 max|·|=8.593e-04 ‖·‖₂=4.722e-02\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.557e-02 max|·|=3.208e-02 ‖·‖₂=4.608e+00\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.883e-04 max|·|=1.016e-03 ‖·‖₂=6.125e-02\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.189e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.673e-04 max|·|=8.256e-04 ‖·‖₂=5.471e-02\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.218e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.20.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.971e-04 max|·|=8.773e-04 ‖·‖₂=6.203e-02\n",
      "base_model.model.transformer.transformer_blocks.20.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.252e-02 ‖·‖₂=4.630e+00\n",
      "base_model.model.transformer.transformer_blocks.20.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.615e-04 max|·|=1.205e-03 ‖·‖₂=7.730e-02\n",
      "base_model.model.transformer.transformer_blocks.20.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.108e-02 max|·|=2.314e-02 ‖·‖₂=4.631e+00\n",
      "base_model.model.transformer.transformer_blocks.20.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.803e-04 max|·|=9.574e-04 ‖·‖₂=5.789e-02\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.567e-02 max|·|=3.228e-02 ‖·‖₂=4.630e+00\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.818e-04 max|·|=9.672e-04 ‖·‖₂=5.800e-02\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.568e-02 max|·|=3.209e-02 ‖·‖₂=4.629e+00\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.977e-04 max|·|=9.406e-04 ‖·‖₂=6.391e-02\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.209e-02 ‖·‖₂=4.611e+00\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.990e-04 max|·|=9.376e-04 ‖·‖₂=6.235e-02\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.205e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.21.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=2.023e-04 max|·|=8.886e-04 ‖·‖₂=6.336e-02\n",
      "base_model.model.transformer.transformer_blocks.21.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.263e-02 ‖·‖₂=4.616e+00\n",
      "base_model.model.transformer.transformer_blocks.21.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.809e-04 max|·|=1.362e-03 ‖·‖₂=8.452e-02\n",
      "base_model.model.transformer.transformer_blocks.21.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.106e-02 max|·|=2.334e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.21.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=2.010e-04 max|·|=1.145e-03 ‖·‖₂=6.444e-02\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.157e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.458e-05 max|·|=3.506e-04 ‖·‖₂=6.568e-03\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.192e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.362e-04 max|·|=1.190e-03 ‖·‖₂=4.804e-02\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.163e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.536e-05 max|·|=3.780e-04 ‖·‖₂=7.727e-03\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.199e-02 ‖·‖₂=4.621e+00\n",
      "base_model.model.transformer.transformer_blocks.3.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.082e-04 max|·|=9.718e-04 ‖·‖₂=3.924e-02\n",
      "base_model.model.transformer.transformer_blocks.3.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.204e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.3.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.320e-04 max|·|=9.980e-04 ‖·‖₂=6.197e-02\n",
      "base_model.model.transformer.transformer_blocks.3.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.105e-02 max|·|=2.283e-02 ‖·‖₂=4.618e+00\n",
      "base_model.model.transformer.transformer_blocks.3.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.306e-04 max|·|=8.893e-04 ‖·‖₂=4.433e-02\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.568e-02 max|·|=3.186e-02 ‖·‖₂=4.632e+00\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.341e-05 max|·|=6.945e-04 ‖·‖₂=2.761e-02\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.183e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.276e-04 max|·|=8.377e-04 ‖·‖₂=4.294e-02\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.202e-02 ‖·‖₂=4.617e+00\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=7.731e-05 max|·|=6.721e-04 ‖·‖₂=2.983e-02\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.251e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.4.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.336e-04 max|·|=9.034e-04 ‖·‖₂=4.431e-02\n",
      "base_model.model.transformer.transformer_blocks.4.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.201e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.4.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.267e-04 max|·|=7.352e-04 ‖·‖₂=5.798e-02\n",
      "base_model.model.transformer.transformer_blocks.4.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.274e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.4.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.292e-04 max|·|=9.598e-04 ‖·‖₂=4.282e-02\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.570e-02 max|·|=3.175e-02 ‖·‖₂=4.633e+00\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.783e-05 max|·|=6.148e-04 ‖·‖₂=3.097e-02\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.186e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.313e-04 max|·|=8.005e-04 ‖·‖₂=4.340e-02\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.171e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.033e-05 max|·|=6.584e-04 ‖·‖₂=3.315e-02\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.558e-02 max|·|=3.180e-02 ‖·‖₂=4.612e+00\n",
      "base_model.model.transformer.transformer_blocks.5.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.649e-04 max|·|=7.487e-04 ‖·‖₂=5.234e-02\n",
      "base_model.model.transformer.transformer_blocks.5.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.196e-02 ‖·‖₂=4.620e+00\n",
      "base_model.model.transformer.transformer_blocks.5.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.379e-04 max|·|=8.880e-04 ‖·‖₂=6.360e-02\n",
      "base_model.model.transformer.transformer_blocks.5.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.104e-02 max|·|=2.276e-02 ‖·‖₂=4.617e+00\n",
      "base_model.model.transformer.transformer_blocks.5.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.320e-04 max|·|=9.568e-04 ‖·‖₂=4.334e-02\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.214e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.356e-05 max|·|=1.007e-03 ‖·‖₂=3.044e-02\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.182e-02 ‖·‖₂=4.628e+00\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.357e-04 max|·|=8.297e-04 ‖·‖₂=4.545e-02\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.557e-02 max|·|=3.189e-02 ‖·‖₂=4.608e+00\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.075e-05 max|·|=8.792e-04 ‖·‖₂=3.206e-02\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.196e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.6.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.867e-04 max|·|=1.207e-03 ‖·‖₂=6.092e-02\n",
      "base_model.model.transformer.transformer_blocks.6.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.559e-02 max|·|=3.190e-02 ‖·‖₂=4.612e+00\n",
      "base_model.model.transformer.transformer_blocks.6.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.258e-04 max|·|=7.365e-04 ‖·‖₂=5.809e-02\n",
      "base_model.model.transformer.transformer_blocks.6.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.106e-02 max|·|=2.272e-02 ‖·‖₂=4.621e+00\n",
      "base_model.model.transformer.transformer_blocks.6.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.538e-04 max|·|=8.099e-04 ‖·‖₂=4.989e-02\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.193e-02 ‖·‖₂=4.614e+00\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.358e-05 max|·|=7.637e-04 ‖·‖₂=2.962e-02\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.189e-02 ‖·‖₂=4.624e+00\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.231e-04 max|·|=7.978e-04 ‖·‖₂=4.131e-02\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.561e-02 max|·|=3.196e-02 ‖·‖₂=4.619e+00\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=8.243e-05 max|·|=7.575e-04 ‖·‖₂=2.959e-02\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.565e-02 max|·|=3.194e-02 ‖·‖₂=4.625e+00\n",
      "base_model.model.transformer.transformer_blocks.7.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.431e-04 max|·|=7.601e-04 ‖·‖₂=4.653e-02\n",
      "base_model.model.transformer.transformer_blocks.7.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.178e-02 ‖·‖₂=4.630e+00\n",
      "base_model.model.transformer.transformer_blocks.7.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.326e-04 max|·|=1.043e-03 ‖·‖₂=6.232e-02\n",
      "base_model.model.transformer.transformer_blocks.7.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.105e-02 max|·|=2.267e-02 ‖·‖₂=4.622e+00\n",
      "base_model.model.transformer.transformer_blocks.7.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.527e-04 max|·|=1.057e-03 ‖·‖₂=4.940e-02\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.191e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.077e-04 max|·|=6.910e-04 ‖·‖₂=3.592e-02\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.571e-02 max|·|=3.176e-02 ‖·‖₂=4.640e+00\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.500e-04 max|·|=7.173e-04 ‖·‖₂=4.789e-02\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.201e-02 ‖·‖₂=4.613e+00\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.180e-04 max|·|=6.702e-04 ‖·‖₂=3.905e-02\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.568e-02 max|·|=3.183e-02 ‖·‖₂=4.630e+00\n",
      "base_model.model.transformer.transformer_blocks.8.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.727e-04 max|·|=8.183e-04 ‖·‖₂=5.383e-02\n",
      "base_model.model.transformer.transformer_blocks.8.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.566e-02 max|·|=3.173e-02 ‖·‖₂=4.627e+00\n",
      "base_model.model.transformer.transformer_blocks.8.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.483e-04 max|·|=1.175e-03 ‖·‖₂=6.961e-02\n",
      "base_model.model.transformer.transformer_blocks.8.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.110e-02 max|·|=2.259e-02 ‖·‖₂=4.634e+00\n",
      "base_model.model.transformer.transformer_blocks.8.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.555e-04 max|·|=9.113e-04 ‖·‖₂=5.005e-02\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_k.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.563e-02 max|·|=3.234e-02 ‖·‖₂=4.623e+00\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_k.lora_B.default.weight  shape=(1024, 64)  mean|·|=9.966e-05 max|·|=9.050e-04 ‖·‖₂=3.547e-02\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_out.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.557e-02 max|·|=3.180e-02 ‖·‖₂=4.607e+00\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_out.0.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.501e-04 max|·|=8.208e-04 ‖·‖₂=4.810e-02\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_q.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.564e-02 max|·|=3.198e-02 ‖·‖₂=4.620e+00\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_q.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.008e-04 max|·|=6.779e-04 ‖·‖₂=3.568e-02\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_v.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.560e-02 max|·|=3.199e-02 ‖·‖₂=4.615e+00\n",
      "base_model.model.transformer.transformer_blocks.9.attn.to_v.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.577e-04 max|·|=7.358e-04 ‖·‖₂=4.974e-02\n",
      "base_model.model.transformer.transformer_blocks.9.ff.ff.0.0.lora_A.default.weight  shape=(64, 1024)  mean|·|=1.562e-02 max|·|=3.184e-02 ‖·‖₂=4.615e+00\n",
      "base_model.model.transformer.transformer_blocks.9.ff.ff.0.0.lora_B.default.weight  shape=(2048, 64)  mean|·|=1.334e-04 max|·|=1.082e-03 ‖·‖₂=6.386e-02\n",
      "base_model.model.transformer.transformer_blocks.9.ff.ff.2.lora_A.default.weight  shape=(64, 2048)  mean|·|=1.107e-02 max|·|=2.265e-02 ‖·‖₂=4.626e+00\n",
      "base_model.model.transformer.transformer_blocks.9.ff.ff.2.lora_B.default.weight  shape=(1024, 64)  mean|·|=1.418e-04 max|·|=8.791e-04 ‖·‖₂=4.537e-02\n",
      "\n",
      "Summary:\n",
      "  Total LoRA parameters : 20,971,520\n",
      "  Combined Frobenius ‖Δ‖₂ : 5.469e+01\n",
      "  Avg per-param scale    : 1.194e-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Extract embedding weights\n",
    "#    adjust the key if your checkpoint nests it differently\n",
    "Wb = sd_before[\"ema_model.transformer.text_embed.text_embed.weight\"]\n",
    "Wa = sd_after[\"base_model.model.transformer.text_embed.text_embed.weight\"]\n",
    "\n",
    "ib = sd_before[\"ema_model.transformer.input_embed.proj.weight\"]\n",
    "ia = sd_after[\"base_model.model.transformer.input_embed.proj.weight\"]\n",
    "\n",
    "# 3) Compute absolute difference\n",
    "delta = (Wa - Wb).abs()\n",
    "\n",
    "idelta = (ib - ia).abs()\n",
    "\n",
    "# 4) Metrics\n",
    "speaker_chg_token_idx = list_str_to_idx([spk_chg_token], vocab_char_map=vocab_char_map)\n",
    "\n",
    "max_overall   = delta.max().item()\n",
    "max_speaker   = delta[speaker_chg_token_idx].max().item()\n",
    "\n",
    "print(\"\\n== Text Embedding Drift ==\")\n",
    "print(f\"→ Max text embedding matrix change |Δ| overall:                  {max_overall:.6f}\")\n",
    "print(f\"→ Max |Δ| on token {speaker_chg_token_idx}: {max_speaker:.6f}\")\n",
    "\n",
    "print(\"\\n== Input Embedding Drift ==\")\n",
    "print(f\"→ Mean input embedding weight change |Δ| overall:                  {idelta.max().item():.6f}\")\n",
    "\n",
    "print(\"== LoRA Weight Scales ==\")\n",
    "inspect_lora_weights(sd_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
